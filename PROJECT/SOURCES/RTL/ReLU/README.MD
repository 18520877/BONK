#  ReLU (Rectified Linear Unit) là Hàm kích hoạt (activation function) mô phỏng tỷ lệ truyền xung qua axon của một neuron thần kinh. ReLU đơn giản lọc các giá trị < 0.
# ![image](https://user-images.githubusercontent.com/79905379/118519127-0779cc00-b763-11eb-9dff-4f67a8f4cf82.png)
