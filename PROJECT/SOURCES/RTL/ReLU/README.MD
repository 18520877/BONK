#  ReLU (Rectified Linear Unit) là Hàm kích hoạt (activation function) mô phỏng tỷ lệ truyền xung qua axon của một neuron thần kinh. ReLU đơn giản lọc các giá trị < 0.
# ![image](https://user-images.githubusercontent.com/79905379/118519284-2d06d580-b763-11eb-9ee7-058a5fcfd0db.png)
